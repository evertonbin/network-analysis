{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Network Analysis - Extracting Features from Network Graphs</h1>\n",
    "<b>Ã‰verton Bin</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>\n",
    "<p>\n",
    "    Through this notebook, we are going to extract features from a company's e-mail network, where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people. The e-mail network can be found in the file <i>email_prediction.txt</i>.\n",
    "</p>\n",
    "<p>\n",
    "    The network also contains the node attributes <i>Department</i> and <i>ManagementSalary</i>. <i>Department</i> indicates the department in the company which the person belongs to, and <i>ManagementSalary</i> indicates whether that person is receiving a management position salary.\n",
    "</p>\n",
    "<p>\n",
    "    <b>Part 1 - Salary Prediction</b>\n",
    "</p>\n",
    "<p>\n",
    "   Using the given network, we are going to identify the people in the network with missing values for the node attribute <i>ManagementSalary</i> and predict whether or not these individuals are receiving a management position salary.\n",
    "</p>\n",
    "<p>\n",
    "    <b>Part 2 - New Connections Prediction</b>\n",
    "</p>\n",
    "<p>\n",
    "    For Part 2, we will predict future connections between employees of the network. The future connections information will be loaded into the variable <i>future_connections</i>. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the <i>Future Connection</i> column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection.\n",
    "</p>\n",
    "<p>\n",
    "    Using the given network and <i>future_connections</i>, we will identify the edges in <i>future_connections</i> with missing values and predict whether or not these edges will have a future connection.\n",
    "</p>\n",
    "<p>\n",
    "    This data was made available by <a href = \"https://umich.edu/\">University of Michigan</a> along with the <a href = \"https://www.coursera.org/learn/python-social-network-analysis\">Applied Social Network Analysis in Python</a> course offered through the <b>Coursera</b> platform, and it can only be accessed in the platform.\n",
    "</p>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries:\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1005\n",
      "Number of edges: 16706\n",
      "Average degree:  33.2458\n"
     ]
    }
   ],
   "source": [
    "# Loading company's email network:\n",
    "G = nx.read_gpickle('email_prediction.txt')\n",
    "\n",
    "# Checking network:\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    We can see the network represents a company with at least 1005 employees (nodes) that have exchanged at least 16706 e-mails (edges) with each other.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 1 - Salary Prediction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    First, we are going to create a pandas dataframe, using the network's nodes as index and extracting the attributes <i>Department</i> and <i>ManagementSalary</i> as features:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>mng_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department  mng_salary\n",
       "0           1         0.0\n",
       "1           1         NaN\n",
       "2          21         NaN\n",
       "3          21         1.0\n",
       "4          21         1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe with nodes as index:\n",
    "df_node = pd.DataFrame(index = G.nodes())\n",
    "\n",
    "# Extracting Department and ManagementSalary as features:\n",
    "df_node['department'] = pd.Series(nx.get_node_attributes(G, 'Department'))\n",
    "df_node['mng_salary'] = pd.Series(nx.get_node_attributes(G, 'ManagementSalary'))\n",
    "df_node.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Next step, we are going to use different centrality measures for networks as features:\n",
    "    <li><b>Degree Centrality</b>: it assumes that important nodes have many connections.</li>\n",
    "    <li><b>Closeness Centrality</b>: it assumes that important nodes are the ones that are close to the others.</li>\n",
    "    <li><b>Betweenness Centrality</b>: it assumes that important nodes connect other nodes.</li>\n",
    "    <li><b>PageRank</b>: it assigns a score of importance for each node, given its in-link proportion (for directed graphs). In our case, it is going to be based on simple node's degree.</li>\n",
    "    <li><b>HITS</b>: it assigns Hub and Authority scores, giving an idea of importance to the nodes according to its connections.</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>mng_salary</th>\n",
       "      <th>degree_cent</th>\n",
       "      <th>closeness_cent</th>\n",
       "      <th>btwn_cent</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>hub</th>\n",
       "      <th>auth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>0.421991</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051793</td>\n",
       "      <td>0.422360</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094622</td>\n",
       "      <td>0.461490</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070717</td>\n",
       "      <td>0.441663</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095618</td>\n",
       "      <td>0.462152</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.003055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department  mng_salary  degree_cent  closeness_cent  btwn_cent  pagerank  \\\n",
       "0           1         0.0     0.043825        0.421991   0.001124  0.001224   \n",
       "1           1         NaN     0.051793        0.422360   0.001195  0.001426   \n",
       "2          21         NaN     0.094622        0.461490   0.006570  0.002605   \n",
       "3          21         1.0     0.070717        0.441663   0.001654  0.001833   \n",
       "4          21         1.0     0.095618        0.462152   0.005547  0.002526   \n",
       "\n",
       "        hub      auth  \n",
       "0  0.000944  0.000944  \n",
       "1  0.001472  0.001472  \n",
       "2  0.002680  0.002680  \n",
       "3  0.002369  0.002369  \n",
       "4  0.003055  0.003055  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Including centrality measures:\n",
    "# Degree Centrality:\n",
    "df_node['degree_cent'] = pd.Series(nx.degree_centrality(G))\n",
    "\n",
    "# Closeness Centrality:\n",
    "df_node['closeness_cent'] = pd.Series(nx.closeness_centrality(G, normalized = True))\n",
    "\n",
    "# Betweenness Centrality:\n",
    "df_node['btwn_cent'] = pd.Series(nx.betweenness_centrality(G, normalized = True, endpoints = False))\n",
    "\n",
    "# PageRank score:\n",
    "df_node['pagerank'] = pd.Series(nx.pagerank(G, alpha = 0.85))\n",
    "\n",
    "# Hub and authority scores:\n",
    "hits = nx.hits(G)\n",
    "df_node['hub'] = pd.Series(hits[0])\n",
    "df_node['auth'] = pd.Series(hits[1])\n",
    "\n",
    "df_node.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    After extracting and creating new features, we are going to split the dataframe into two parts: one with information about Management Salary, and other with missing Management Salary information, which we want to predict.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting observations with missing and not missing ManagementSalary information:\n",
    "df_pred = df_node[df_node['mng_salary'].isnull()]\n",
    "df = df_node[df_node['mng_salary'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting features and target:\n",
    "feat_columns = ['department', 'degree_cent', 'closeness_cent', 'btwn_cent', 'pagerank', 'hub', 'auth']\n",
    "X = df[feat_columns]\n",
    "y = df['mng_salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    With the dataframe splitted into predictive and target features, we are going to split it into train and test sets.\n",
    "</p>\n",
    "<p>\n",
    "    After that, using train set, we are going to use <i>GridSearchCV</i> to look for best parameters to train a <i>Random Forest Classifier</i> model:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [15, 30, 50, 75], 'max_features': [2, 3, 4, 5], 'max_depth': [None, 2, 3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting data into train and test sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 101)\n",
    "\n",
    "# Using GreadSearchCV to find the best parameters for the Random Forest Classifier:\n",
    "rand_for = RandomForestClassifier()\n",
    "grid_values = {'n_estimators': [15, 30, 50, 75], 'max_features': [2, 3, 4, 5], 'max_depth': [None, 2, 3, 4, 5]}\n",
    "grid_rand_for_auc = GridSearchCV(rand_for, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_rand_for_auc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90431590058241273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best ROC score:\n",
    "grid_rand_for_auc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'max_features': 2, 'n_estimators': 75}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters:\n",
    "grid_rand_for_auc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Using the GridSearchCV best parameters, we will finally train the Random Forest model in order to predict Management Salary for the employees with missing salary information.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc AUC score for test set: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Training Random Forest model with best parameters:\n",
    "random_forest = RandomForestClassifier(max_depth = 5, max_features = 4, n_estimators = 50, random_state = 100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the model with test set:\n",
    "y_pred_test = random_forest.predict(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print('Roc AUC score for test set: '+ str(round(roc_auc, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0.122229\n",
       "2       1.000000\n",
       "5       1.000000\n",
       "8       0.088217\n",
       "14      0.101852\n",
       "18      0.198015\n",
       "27      0.127553\n",
       "30      0.219130\n",
       "31      0.367688\n",
       "34      0.032050\n",
       "37      0.044272\n",
       "40      0.132729\n",
       "45      0.127597\n",
       "54      0.341600\n",
       "55      0.168802\n",
       "60      0.138372\n",
       "62      1.000000\n",
       "65      0.966667\n",
       "77      0.078712\n",
       "79      0.369308\n",
       "97      0.019452\n",
       "101     0.029165\n",
       "103     0.178275\n",
       "108     0.131455\n",
       "113     0.153580\n",
       "122     0.017881\n",
       "141     0.275077\n",
       "142     0.980000\n",
       "144     0.090000\n",
       "145     0.118164\n",
       "          ...   \n",
       "913     0.016159\n",
       "914     0.028963\n",
       "915     0.006407\n",
       "918     0.024498\n",
       "923     0.003262\n",
       "926     0.016671\n",
       "931     0.016671\n",
       "934     0.008348\n",
       "939     0.003797\n",
       "944     0.010387\n",
       "945     0.003797\n",
       "947     0.100891\n",
       "950     0.252931\n",
       "951     0.004833\n",
       "953     0.016159\n",
       "959     0.004836\n",
       "962     0.003797\n",
       "963     0.248445\n",
       "968     0.006630\n",
       "969     0.006661\n",
       "974     0.006804\n",
       "984     0.008348\n",
       "987     0.007959\n",
       "989     0.005059\n",
       "991     0.022170\n",
       "992     0.005059\n",
       "994     0.010387\n",
       "996     0.006407\n",
       "1000    0.006804\n",
       "1001    0.007959\n",
       "Length: 252, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making probability prediction for missing ManagementSalary:\n",
    "X_pred = df_pred[feat_columns]\n",
    "y_pred = random_forest.predict_proba(X_pred)\n",
    "\n",
    "# Creating a pandas Series indicating the employee's probability of having a Management Salary:\n",
    "prob_list = [prob[1] for prob in y_pred]\n",
    "mng_salary_prob = pd.Series(data = prob_list, index = df_pred.index.values)\n",
    "\n",
    "mng_salary_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 2 - New Coonections Prediction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    First, we are going to load the <i>Future Connections</i> file that indicates whether the nodes connected or not, or if the information is missing.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Future Connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(6, 840)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 197)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(620, 979)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(519, 872)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(382, 423)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(97, 226)</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(349, 905)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(429, 860)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(309, 989)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(468, 880)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Future Connection\n",
       "(6, 840)                  0.0\n",
       "(4, 197)                  0.0\n",
       "(620, 979)                0.0\n",
       "(519, 872)                0.0\n",
       "(382, 423)                0.0\n",
       "(97, 226)                 1.0\n",
       "(349, 905)                0.0\n",
       "(429, 860)                0.0\n",
       "(309, 989)                0.0\n",
       "(468, 880)                0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_connections = pd.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})\n",
    "future_connections.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    As we did in Part 1, we will now create a dataframe with information about the edges, instead of nodes.\n",
    "</p>\n",
    "<p>\n",
    "    Since we are interested in future connections, our dataframe will have, as index, all the possible edges (e-mail link between employees) that haven't happened yet. For that, we use <b>non_edges</b> function:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating dataframe for the edges:\n",
    "df_edges = pd.DataFrame(index=nx.non_edges(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    After that, we are going to use link measures as features:\n",
    "</p>\n",
    "    <li><b>Common Neighbors</b>: the number of common neighbors define whether two nodes are likely to connect.</li>\n",
    "    <li><b>Jaccard Coefficient</b>: it is the common neighbors normalized by the total number of neighbors between the two nodes.</li>\n",
    "    <li><b>Resource Allocation</b>: indicates the fraction of 'resource' that one node can send to another through their common neighbors - it penalizes common neighbors that have lots of neighbors themselves.</li>\n",
    "    <li><b>Preferential Attachment</b>: it assumes that nodes with high degree are more likely to get more neighbors.</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_neigh</th>\n",
       "      <th>jacc</th>\n",
       "      <th>res_alloc</th>\n",
       "      <th>pref_attach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 2)</th>\n",
       "      <td>6</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>4180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 3)</th>\n",
       "      <td>3</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>3124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 4)</th>\n",
       "      <td>3</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>4224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 7)</th>\n",
       "      <td>4</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.061668</td>\n",
       "      <td>3168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 8)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        common_neigh      jacc  res_alloc  pref_attach\n",
       "(0, 2)             6  0.045802   0.055340         4180\n",
       "(0, 3)             3  0.027273   0.021388         3124\n",
       "(0, 4)             3  0.022222   0.021388         4224\n",
       "(0, 7)             4  0.036364   0.061668         3168\n",
       "(0, 8)             1  0.012821   0.011628         1628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating edge based features:\n",
    "# Common Neighbors:\n",
    "common_neigh = [(e[0], e[1], len(list(nx.common_neighbors(G, e[0], e[1])))) for e in df_edges.index]\n",
    "df_edges['common_neigh'] = [cn[2] for cn in common_neigh]\n",
    "\n",
    "# Jaccard Coefficient\n",
    "df_edges['jacc'] = [i[2] for i in nx.jaccard_coefficient(G, df_edges.index)]\n",
    "\n",
    "# Resource Allocation:\n",
    "df_edges['res_alloc'] = [i[2] for i in nx.resource_allocation_index(G, df_edges.index)]\n",
    "\n",
    "# Preferential Attachment:\n",
    "df_edges['pref_attach'] = [i[2] for i in nx.preferential_attachment(G, df_edges.index)]\n",
    "\n",
    "df_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Now, we are going to merge the edge dataframe with the future_connections dataframe by index:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_neigh</th>\n",
       "      <th>jacc</th>\n",
       "      <th>res_alloc</th>\n",
       "      <th>pref_attach</th>\n",
       "      <th>Future Connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 2)</th>\n",
       "      <td>6</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>0.055340</td>\n",
       "      <td>4180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 3)</th>\n",
       "      <td>3</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>3124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 4)</th>\n",
       "      <td>3</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>4224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 7)</th>\n",
       "      <td>4</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.061668</td>\n",
       "      <td>3168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 8)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>1628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        common_neigh      jacc  res_alloc  pref_attach  Future Connection\n",
       "(0, 2)             6  0.045802   0.055340         4180                0.0\n",
       "(0, 3)             3  0.027273   0.021388         3124                0.0\n",
       "(0, 4)             3  0.022222   0.021388         4224                0.0\n",
       "(0, 7)             4  0.036364   0.061668         3168                0.0\n",
       "(0, 8)             1  0.012821   0.011628         1628                0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging edges dataframes into one:\n",
    "df_edges = df_edges.merge(future_connections, left_index = True, right_index = True)\n",
    "df_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    As we did before, we are going to separate observations with missing future connections information from the others.\n",
    "</p>\n",
    "<p>\n",
    "    After that, we are going to split data into train and test sets:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting dataframe:\n",
    "df_e = df_edges[df_edges['Future Connection'].isnull() == False]\n",
    "df_e_pred = df_edges[df_edges['Future Connection'].isnull()]\n",
    "\n",
    "# Creating train and test sets:\n",
    "e_feat_columns = ['common_neigh', 'jacc', 'res_alloc', 'pref_attach']\n",
    "X_e = df_e[e_feat_columns]\n",
    "y_e = df_e['Future Connection']\n",
    "\n",
    "X_e_train, X_e_test, y_e_train, y_e_test = train_test_split(X_e, y_e, test_size = .2, random_state = 201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    With <i>GridSearchCV</i>, we are going to search for the best parameters for this new model:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=300,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [15, 30, 50, 75, 100], 'max_features': [2, 3, 4], 'max_depth': [None, 2, 3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using GreadSearchCV to find the best parameters for the Random Forest Classifier:\n",
    "rand_for = RandomForestClassifier(random_state = 300)\n",
    "grid_values = {'n_estimators': [15, 30, 50, 75, 100], 'max_features': [2, 3, 4], 'max_depth': [None, 2, 3, 4, 5]}\n",
    "grid_rand_for_auc = GridSearchCV(rand_for, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_rand_for_auc.fit(X_e_train, y_e_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_features': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best ROC score:\n",
    "grid_rand_for_auc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91128738312845403"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters:\n",
    "grid_rand_for_auc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc AUC score for test set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Training Random Forest model with best parameters:\n",
    "random_forest_e = RandomForestClassifier(max_depth = 5, max_features = 2, n_estimators = 100, random_state = 300)\n",
    "random_forest_e.fit(X_e_train, y_e_train)\n",
    "\n",
    "# Evaluating the model with test set:\n",
    "y_e_pred_test = random_forest_e.predict(X_e_test)\n",
    "roc_auc_e = roc_auc_score(y_e_test, y_e_pred_test)\n",
    "\n",
    "print('Roc AUC score for test set: '+ str(round(roc_auc_e, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Finally, we are making link prediction for the edges:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)          0.058250\n",
       "(0, 19)         0.093424\n",
       "(0, 20)         0.248937\n",
       "(0, 35)         0.016786\n",
       "(0, 38)         0.013170\n",
       "(0, 42)         0.819971\n",
       "(0, 43)         0.019588\n",
       "(0, 50)         0.013088\n",
       "(0, 53)         0.667055\n",
       "(0, 54)         0.066407\n",
       "(0, 62)         0.446667\n",
       "(0, 63)         0.073693\n",
       "(0, 69)         0.026623\n",
       "(0, 72)         0.013088\n",
       "(0, 83)         0.188604\n",
       "(0, 90)         0.031126\n",
       "(0, 91)         0.016883\n",
       "(0, 95)         0.140424\n",
       "(0, 100)        0.044381\n",
       "(0, 106)        0.970887\n",
       "(0, 108)        0.016870\n",
       "(0, 109)        0.013088\n",
       "(0, 110)        0.013088\n",
       "(0, 118)        0.013170\n",
       "(0, 122)        0.032400\n",
       "(0, 131)        0.067190\n",
       "(0, 133)        0.719686\n",
       "(0, 140)        0.071822\n",
       "(0, 149)        0.295241\n",
       "(0, 151)        0.013170\n",
       "                  ...   \n",
       "(988, 989)      0.013088\n",
       "(988, 996)      0.013088\n",
       "(988, 997)      0.060013\n",
       "(988, 1000)     0.013088\n",
       "(988, 1002)     0.013088\n",
       "(989, 994)      0.013088\n",
       "(989, 996)      0.013088\n",
       "(989, 1003)     0.013088\n",
       "(989, 1004)     0.013088\n",
       "(990, 994)      0.013088\n",
       "(990, 998)      0.028423\n",
       "(991, 994)      0.013088\n",
       "(991, 999)      0.013088\n",
       "(991, 1003)     0.013088\n",
       "(992, 994)      0.013088\n",
       "(992, 995)      0.013088\n",
       "(992, 997)      0.013088\n",
       "(992, 1000)     0.013088\n",
       "(993, 1000)     0.013088\n",
       "(994, 996)      0.013088\n",
       "(995, 998)      0.013088\n",
       "(995, 1000)     0.013088\n",
       "(996, 997)      0.013088\n",
       "(997, 998)      0.013088\n",
       "(997, 1004)     0.013088\n",
       "(998, 999)      0.013088\n",
       "(1000, 1002)    0.013088\n",
       "(1000, 1003)    0.013088\n",
       "(1000, 1004)    0.013088\n",
       "(1001, 1002)    0.013088\n",
       "Length: 122112, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making probability prediction for missing Future Connection:\n",
    "X_e_pred = df_e_pred[e_feat_columns]\n",
    "y_e_pred = random_forest_e.predict_proba(X_e_pred)\n",
    "\n",
    "# Creating a pandas Series indicating the edge's probability of happening (two employees create a connection):\n",
    "prob_e_list = [prob_e[1] for prob_e in y_e_pred]\n",
    "fut_conn_prob = pd.Series(data = prob_e_list, index = df_e_pred.index.values)\n",
    "\n",
    "fut_conn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "BGNwe",
   "launcher_item_id": "rMoj0",
   "part_id": "E2zRG"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
